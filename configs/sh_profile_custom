export LS_OPTIONS='--color=auto'
alias ls='ls $LS_OPTIONS'
alias ll='ls $LS_OPTIONS -lh'
alias l='ls $LS_OPTIONS -lAh'

alias grep="grep --color=auto"
alias fgrep="fgrep --color=auto"
alias egrep="egrep --color=auto"

#if type nerdctl >/dev/null; then
#	alias docker=nerdctl
#	alias docker-compose="nerdctl compose"
#fi

alias csv="sed 's/,/ ,/g' | column -t -s,"

alias reset="reset && printf '\033[2J\033[3J\033[1;1H'"

# export LC_CTYPE="en_US.UTF-8"
# IF YOU GET A LOCALE UNSUPPORTED ERROR
# ENABLE MISSING LOCALES: sudo vim /etc/locale.gen
# THEN REGENERATE: sudo locale-gen

alias d='docker'

alias dive='docker run --rm -it -v /var/run/docker.sock:/var/run/docker.sock wagoodman/dive:latest'

alias lzd='docker run --rm -it -v /var/run/docker.sock:/var/run/docker.sock lazyteam/lazydocker'

alias dfimage="docker run --rm -i -v /var/run/docker.sock:/var/run/docker.sock alpine/dfimage"

alias trivy="docker run --rm -t -v /var/run/docker.sock:/var/run/docker.sock ghcr.io/aquasecurity/trivy:latest image --scanners vuln --ignore-unfixed"

alias whitespace="sed 's/ /·/g;s/\t/￫/g;s/\r/§/g;s/$/¶/g'"

alias bfg='docker run --rm -it -v "$(pwd):/work" -u $(id -u ${USER}):$(id -g ${USER}) jtmotox/bfg'

alias yqc='docker run --rm -i backplane/pygmentize -l yaml'

alias clear='printf "\033c"' # workaround that prevents the original clear command from clearing the tmux history

alias bat='bat --paging=always'

# FIX LOCALE WARNINGS
export LC_CTYPE=en_US.UTF-8
export LC_ALL=en_US.UTF-8

# GITLEAKS REPO SCANNER
if [ "$(uname)" = "Darwin" ]; then
    alias glscan='docker run --rm -it -v "$HOME/Downloads:$HOME/Downloads" -v "$(pwd):$(pwd)" -w "$(pwd)" -u $(id -u):$(id -g) -e repo_scan_log_dir="$HOME/Downloads" -e no_git -e secrets_in_logs docker-ngdc.repo.east1.ncloud.netapp.com/devexp-engg/gitleaks-repo-scanner:latest'
elif [ "$(uname)" = "Linux" ]; then
	alias glscan='docker run --rm -it -v "/tmp:/tmp" -v "$(pwd):$(pwd)" -w "$(pwd)" -u $(id -u):$(id -g) -e no_git -e secrets_in_logs docker-ngdc.repo.east1.ncloud.netapp.com/devexp-engg/gitleaks-repo-scanner:latest'
fi

# FUNCTIONS TO URL ENCODE AND DECODE
urlencode() { if test ! -t 0; then URL_STRING="$(cat)"; else URL_STRING="$1"; fi; perl -MURI::Escape -e 'print uri_escape($ARGV[0]);' "${URL_STRING}"; }
urldecode() { if test ! -t 0; then URL_STRING="$(cat)"; else URL_STRING="$1"; fi; perl -MURI::Escape -e 'print uri_unescape($ARGV[0]);' "${URL_STRING}"; }

# FUNCTION TO DECODE JWT TOKEN
jwtdecode() {
	if test ! -t 0; then JWT_STRING="$(cat)"; else JWT_STRING="$1"; fi
	JWT_DOT_COUNT="$(echo "${JWT_STRING}" | grep -o "\." | wc -l)"
	if [ "${JWT_DOT_COUNT}" -eq 2 ]; then
		HEADER="$(echo "${JWT_STRING}" | cut -d "." -f 1 | base64 -d | jq)"
		PAYLOAD="$(echo "${JWT_STRING}" | cut -d "." -f 2)"
		SIGNATURE="$(echo "${JWT_STRING}" | cut -d "." -f 3)"
	elif [ "${JWT_DOT_COUNT}" -eq 0 ]; then
		HEADER="na"
		PAYLOAD=$(echo "${JWT_STRING}")
		SIGNATURE="na"
	else
		echo "Invalid JWT string"
		return 1
	fi
	PAYLOAD="$(echo "${PAYLOAD}====" | fold -w 4 | sed '$ d' | tr -d '\n' | base64 -d -i)"
	# echo "Header:"
	# if [ "${HEADER}" != "na" ] && type jq >/dev/null; then echo "${HEADER}" | jq; else echo "${HEADER}"; fi
	# echo "Payload:"
	if type jq >/dev/null; then echo "${PAYLOAD}" | jq; else echo "${PAYLOAD}"; fi
	# echo "Signature:"
	# echo "${SIGNATURE}"
}

# FUNCTION TO UPDATE DOTFILES AND APPLY CHANGES
dotu() {
	if [ ! -d "${dotdir}" ]; then echo "Unable to determine dotfiles directory"; return 1; fi
	git -C "${dotdir}" pull
	"${dotdir}/setup.sh"
}

# FUNCTION TO GIVE VSC URL
vsc() {
	relpath=$@
	if [ "${relpath}" = "" ]; then relpath="$(pwd)"; fi
	if [ -f "${relpath}" ]; then relpath="$(dirname "${relpath}")"; fi
	abspath="$(eval cd ${relpath} 2>/dev/null && pwd)"
	if [ "${abspath}" = "" ]; then echo "Path not found: '${relpath}'"; return 1; fi
	if hostname -s | grep '^vmwdxp' >/dev/null 2>&1; then
		tunnel_url="https://vsc:4443/?folder="
	elif systemctl --user status code-tunnel.service >/dev/null 2>&1; then
		tunnel_name="$(cat ~/.vscode/cli/code_tunnel.json | sed -E 's/^.*\"name\":\"([^\"]*).*/\1/')"
		tunnel_url="https://vscode.dev/tunnel/${tunnel_name}"
	else
		echo "Unable to determine tunnel url"
		echo "Try running `systemctl daemon-reload` and try again"
		return 1
	fi
	echo "${tunnel_url}${abspath}"
}

# FUNCTION TO CALCULATE COMPRESSED DOCKER IMAGE SIZE
docker_size() {
	previous_pipefail=$(set +o | grep pipefail)
	set -o pipefail
	trap 'trap - ERR; eval "${previous_pipefail}"; return 1;' ERR
	IMAGE=$1
	if [ "${IMAGE}" = "" ]; then echo "You must specify the image you want to calculate."; return 1; fi
	echo "Calculating compressed image size . . ."
	docker save "${IMAGE}" | gzip >/tmp/test.tgz
	du -h /tmp/test.tgz | cut -f1
	rm -f /tmp/test.tgz 2>/dev/null || true
	trap - ERR
}
alias docker-size="docker_size"

# STRIP ANSI CHARACTERS SUCH AS COLORS FROM TEE OUTPUT FILE
teee() {
	type tee &>/dev/null || { echo "The 'tee' command is required for 'teee'"; return 1; }
    [ $# -eq 1 ] || { echo "Usage: teee <filename>"; return 1; }
	tee >(sed $'s/\033[[][^A-Za-z]*[A-Za-z]//g' > $1)
}
# teee() {
#     type tee >/dev/null || { echo "The 'tee' command is required for 'teee'"; return 1; }
#     if [ $# -ne 1 ]; then
#         echo "Usage: teee <filename>"
#         return 1
#     fi
# 	tmp_file=$(mktemp)
# 	awk '{gsub(/\x1B\[([0-9]{1,2}(;[0-9]{1,2})?)?[mGK]/,""); print}' > "$tmp_file"
# 	tee "$tmp_file" > "$1"
# 	rm "$tmp_file"
# }

if type ts &>/dev/null; then
	alias ts="ts '%Y-%m-%d %H:%M:%.S %Z -'"
fi

# SCAN FOR CREDENTIALS
gitleaks_scan() {
	config_file=~/.gitleaks/leaky-repo-custom-new.toml
	if [ ! -d .git ]; then
		echo "WARNING: Not in a git directory '$PWD'"
		printf "%s " "Press enter to continue"
		read ans
	fi
	TEMPDIR="$(mktemp -d)"
	echo "TEMPDIR: ${TEMPDIR}"
	chmod 777 "${TEMPDIR}"
	if [ ! -f "${config_file}" ]; then
		echo "WARNING: Config file not found: '${config_file}'"
		config_file="${TEMPDIR}/config.toml"
		printf "[extend]\nuseDefault = true" >"${config_file}"
		# return 1
	fi
	echo "Scanning . . ."
	docker run --rm -v "${config_file}:/config.toml" -v "$PWD":/path -v "${TEMPDIR}:${TEMPDIR}" -w /path ghcr.io/zricethezav/gitleaks:latest detect --config=/config.toml --no-banner -f json -r "${TEMPDIR}/results.json"
	if cat "${TEMPDIR}/results.json" | jq -r '.[] | "Entry:" + .File + "ø" + .Secret + "ø" + .Description + "ø" + .Commit' | grep '^Entry:' | sed 's/^Entry://' | sort | column -s 'ø' -t | uniq; then
		echo "not removing tempdir"
		# rm -rf "${TEMPDIR}"
	else
		echo "There was an error parsing the results"
		echo "Results are stored at '${TEMPDIR}/results.json'"
		echo "Make sure to delete the results once you are finished"
		return 1
	fi
}
alias gitleaks-scan="gitleaks_scan"

# SCAN IMAGE FOR CREDENTIALS
image_secret_scanner() {
	IMAGE_SCAN_RESULTS_FILE="image-scan-results.json"
	rm -f "${IMAGE_SCAN_RESULTS_FILE}"
	docker run --rm -v $(pwd):/home/deepfence/output -v /var/run/docker.sock:/var/run/docker.sock deepfenceio/deepfence_secret_scanner:latest --json-filename="${IMAGE_SCAN_RESULTS_FILE}" -image-name $1 >/dev/null
	cat "./${IMAGE_SCAN_RESULTS_FILE}" | jq -r '.Secrets[] | ."Matched Rule Name" + "ø" + .Severity + "ø" + ("/" + ."Full File Name")' | sort | column -s 'ø' -t | uniq
	echo
	echo "-- ENVIRONMENT VARIABLES --"
	docker run --rm $1 env
}
alias image-secret-scanner="image_secret_scanner"

# PERFORM DIFF AGAINST BFG REPORT
bfg_diff() {
	map_file="$1"
	[ "$(basename "${map_file}")" != "object-id-map.old-new.txt" ] && { echo "You need to provide the 'object-id-map.old-new.txt' file that bfg generated"; return 1; }
	[ ! -f "${map_file}" ] && { echo "File not found: '${map_file}'"; return 1; }
	git rev-parse --is-inside-work-tree >/dev/null 2>&1 || { echo "You need to be in a git directory to perform this action"; return 1; }
	echo "Comparing . . ."
	cat "$1" | while read -r l; do eval git --no-pager diff --color=never --unified=0 $l; done | grep -E '^(\+|\-)\s' | awk '!x[$0]++' | awk '/^+/ { printf "\033[32m%s\033[0m\n", $0 } /^-/ { printf "\033[31m%s\033[0m\n", $0 }'
	echo "Done"
}
alias bfg-diff=bfg_diff


export DOCKER_BUILDKIT=1
export BUILDKIT_PROGRESS=plain
export DOCKER_SCAN_SUGGEST=false

# DE-ANSI CONTENT
deansi() { cat | sed -r 's/^([0-9]|-|T|:|\.|Z)*\s//' | sed 's/\x1B[@A-Z\\\]^_]\|\x1B\[[0-9:;<=>?]*[-!"#$%&'"'"'()*+,.\/]*[][\\@A-Z^_`a-z{|}~]\|\x1B\][0-9;]*.*\x07//g'; }

# FUNCTION TO ALLOW yq WITHOUT EXTRA ARGS
yq_disabled() {
	if [[ "$@" == "" ]]; then
		command yq r - -C
	else
		command yq $@
	fi
}

# REPLACEMENT WATCH COMMAND THAT SOURCES YOUR ENVIRONMENT
watchenv() {
    args=("$@")
    num_args=${#args[@]}
    last_argument=${args[$((num_args))]}
    remaining_arguments=${args[@]:0:$((num_args-1))}
	command watch $remaining_arguments "NO_ZSH_CLEAR=true NO_ZSH_TITLE=true zsh -i -c '$last_argument'"
}

# FUNCTION TO PARSE ANSIBLE LOG TASKS
ansible_task_parse() {
	if [[ "$1" == "" ]]; then echo "You need to pass a file to parse"; return 1; fi
	if [[ ! -f "$1" ]]; then echo "File not found: $1"; return 1; fi
	cat "$1" \
		| sed 's/\x1b\[[0-9;]*m//g' \
		| grep -E '^TASK|^\w+: \[' \
		| grep -v '^skipping:' \
		| grep -E '^\w+:' -B1 \
		| grep -v '^--$' \
		| grep '^TASK' \
		| grep -v '\(debug\|set_fact\|include_tasks\|include_vars\|fail\)\]' \
		| grep -v '\[include_role' \
		| perl -p -e 's/.*: (.*)\] *.*/\1/' \
		| grep -v '^TASK' \
		| awk '!x[$0]++' \
		| cat -n \
		| sed -r "s/^\s+//g" \
		| sed "s/^[0-9]*/& \> /g"
}
alias ansible-task-parse="ansible_task_parse"

# FUNCTION TO ALLOW WINDOWS WINGET TO RUN IN WSL
command -v winget.exe >/dev/null 2>&1 && { alias winget="winget.exe"; } || true
wingetu() {
	command -v winget.exe >/dev/null || { echo "'winget.exe' not found"; return 1; }
	local upgrade_list_full=$(winget.exe upgrade)
	local TITLE="FULL LIST"
	printf '%*s\n' "$((${COLUMNS:-$(tput cols)}-${#TITLE}-2))" '' | tr ' ' - | perl -p -e "s/^(---)/\1 ${TITLE} /" | perl -p -e "s/^(---)\s\s(-+)/\1\2--/"
	echo -e "${upgrade_list_full}"
	local upgrade_list_filtered=$(echo "${upgrade_list_full}" | tr -d "\r" | grep 'winget$' | perl -p -e 's/^(.*?)\s+([^\s<]+)(?:\s|<)+([^\s]+)\s+([^\s]+)\s+\w+$/\2~\3~\4/' | grep -v '\sUnknown\s' | grep -vE 'Microsoft.VisualStudioCode')
	if [[ "${upgrade_list_filtered}" == "" ]]; then
		echo "Nothing to upgrade"
		return
	fi
	local TITLE="UPGRADABLE LIST"
	printf '%*s\n' "$((${COLUMNS:-$(tput cols)}-${#TITLE}-2))" '' | tr ' ' - | perl -p -e "s/^(---)/\1 ${TITLE} /" | perl -p -e "s/^(---)\s\s(-+)/\1\2--/"
	echo -e "${upgrade_list_filtered}" | sort | column -t -s '~' | sed 's/.*/- &/'
	printf '%*s\n' "${COLUMNS:-$(tput cols)}" '' | tr ' ' -
	while true; do
		printf "Do you want to continue? [Y/n] "
		read yn
		case $yn in
			[Yy]* ) break;;
			[Nn]* ) return 0;;
			* ) echo "Please answer yes or no.";;
		esac
	done
	echo -e "${upgrade_list_filtered}" | awk -F '~' '{print $1}' | xargs -I % sh -c "echo Upgrading: %; winget.exe upgrade -e %;"
}

# FUNCTION THAT EXECUTES COMMANDS WHEN A FILE/DIRECTORY IS MODIFIED
# saveexec /tmp/test.sh
# saveexec /tmp "/test.sh foo bar"
saveexec() {
	if command -v inotifywait >/dev/null; then
		local WATCHER="inotifywait"
	elif command -v fswatch >/dev/null; then
		local WATCHER="fswatch"
	else
		echo "You must install 'inotifywait' for linux or 'fswatch' for macos."
		return 1
	fi
	local SHELL="${SHELL:-$(command -v sh)}"
	"${SHELL}" -c "env >/tmp/fake.txt"
	local WATCH="$1"
	shift
	ls -ld "${WATCH}" >/dev/null || return 1
	if [ $# -gt 0 ]; then
		local EXEC="$@"
	elif [ -f "${WATCH}" ]; then
		local EXEC="${WATCH}"
	else
		echo "What do you want me to do when this directory is modified?"
		return 1
	fi
	echo -ne "\a"
	clear
	"${SHELL}" -c "${EXEC}" || true
	while true; do
		if [ "${WATCHER}" = "inotifywait" ]; then
			inotifywait --quiet -e modify "${WATCH}"
		elif [ "${WATCHER}" = "fswatch" ]; then
			local MODIFIED="$(fswatch --one-event "${WATCH}")"
		else
			echo "No watcher found"
			return 1
		fi
		echo -ne "\a"
		clear
		sleep 0.1
		"${SHELL}" -c "${EXEC}" || true
	done
}

# FUNCTION TO RUN PRISMA SCAN
prisma() {
	if ! test -f ~/.prisma.conf; then
		echo "Prisma Configuration not found."
		return 1
	fi
	clear
	scan_image="$1" \
	bash -c '
		. ~/.prisma.conf
		#ENCRYPT: echo "username:password" | openssl aes-256-cbc -a -salt -pass pass:"YourEncryptionPasswordHere"
		PRISMA_CREDS=$(echo "${prisma_creds_enc}" | openssl aes-256-cbc -d -a -pass pass:"${prisma_enc}:s@lt")
		PRISMA_USER=$(echo "${PRISMA_CREDS}" | cut -d ":" -f 1)
		PRISMA_PASS=$(echo "${PRISMA_CREDS}" | cut -d ":" -f 2-)
		if [ "${prisma_enc_debug}" == "true" ]; then
			read -p "Debugging enc details. Press enter to continue . . ."
			echo "$PRISMA_USER"
			echo "$PRISMA_PASS"
			exit 0
		fi
		if [[ ! -f /tmp/twistcli ]]; then
			if [ "$(uname -s)" == "Linux" ]; then
				prisma_link="twistcli"
			elif [ "$(uname -s)" == "Darwin" ]; then
				prisma_link="osx/twistcli"
			else
				echo "Unknown platform: $(uname -s)"
				exit 1
			fi
			echo "Downloading twistcli . . ."
			curl -s -u "${PRISMA_USER}":"${PRISMA_PASS}" --output /tmp/twistcli "${prisma_url}/api/v1/util/${prisma_link}"
			echo "done"
		fi
		if [[ "$(docker images -q ${scan_image} 2> /dev/null)" == "" ]]; then
			echo "Pulling image . . ."
			docker pull ${scan_image}
		fi
		chmod 755 /tmp/twistcli
		echo "Scanning . . ."
		/tmp/twistcli images scan --address "${prisma_url}" --user "${PRISMA_USER}" --password "${PRISMA_PASS}" --output-file /tmp/${scan_image}.txt --details ${scan_image}
	'
}

# FUNCTION TO GET COMPILED AZURE PIPELINE YAML
pipeline() {
	display_help() { echo "pipeline <project> <pipeline_id> <branch>"; return; }
	PROJECT="$1"
	PIPELINE_ID="$2"
	BRANCH="$3"
	test -z "${PROJECT}" && { echo "Missing parameter"; display_help; return 1; }
	test -z "${PIPELINE_ID}" && { echo "Missing parameter"; display_help; return 1; }
	test -z "${BRANCH}" && BRANCH="master"
	TMP_FILE="/tmp/test.txt"
	#ENCRYPT: echo "username:password" | openssl aes-256-cbc -a -iter 100000 -salt -pass pass:"YourEncryptionPasswordHere"
	PIPELINE_ENC="$(. ~/.pipeline.conf && echo "${pipeline_enc}")"
	PIPELINE_PAT_ENC="$(. ~/.pipeline.conf && echo "${pipeline_pat_enc}")"
	PIPELINE_CREDS=$(echo "${PIPELINE_PAT_ENC}" | openssl aes-256-cbc -d -a -iter 100000 -pass pass:"${PIPELINE_ENC}:s@lt")
	PIPELINE_CREDS_B64="$(printf "${PIPELINE_CREDS}" | base64 -w 0)"
	curl -sS --request POST \
		--url "https://dev.azure.com/netapp-ngdc/${PROJECT}/_apis/pipelines/${PIPELINE_ID}/preview?api-version=6.1-preview.1" \
		--header "authorization: Basic ${PIPELINE_CREDS_B64}" \
		--header "content-type: application/json" \
		--data '{"previewRun": true, "resources": {"repositories": {"self": {"refName": "refs/heads/'${BRANCH}'"}}}}' \
	>"${TMP_FILE}"
	finalYaml="$(cat "${TMP_FILE}" | jq -r '.finalYaml')"
	if [ "${finalYaml}" = "" ] || [ "${finalYaml}" = "null" ]; then
		cat "${TMP_FILE}"
		echo "THERE WAS AN ERROR"
		return 1
	fi
	echo "${finalYaml}"
}

test -e "${HOME}/.iterm2_shell_integration.bash" && { source "${HOME}/.iterm2_shell_integration.bash"; } || true

# FUNCTION TO UPDATE ALL PACKAGES
update() {
	if [ "$(whoami)" = "root" ]; then
		echo "WARNING! You are running as root. This is not recommended."
		while true; do
			printf "Do you want to continue (y/n)? "
			read yn
			case $yn in
				[Yy]* ) break;;
				[Nn]* ) return 1;;
				* ) echo "Please answer yes or no."; continue;;
			esac
		done
	else
		if ! sudo whoami >/dev/null 2>&1; then
			echo "You must have sudo privileges to run this command"
			return 1
		fi
		SUDO="sudo"
	fi
	if type apt-get &>/dev/null; then
		echo "Updating apt-get..."
		$SUDO apt-get update && $SUDO apt-get upgrade -y && $SUDO apt-get autoremove -y
	fi
	if type pacman &>/dev/null; then
		echo "Updating pacman..."
		$SUDO pacman -Syu
	fi
	if type dnf &>/dev/null; then
		echo "Updating dnf..."
		$SUDO dnf update -y
	fi
	if type yum &>/dev/null; then
		echo "Updating yum..."
		$SUDO yum update -y
	fi
	if type zypper &>/dev/null; then
		echo "Updating zypper..."
		$SUDO zypper update -y
	fi
	if type apk &>/dev/null; then
		echo "Updating apk..."
		$SUDO apk update && $SUDO apk upgrade
	fi
	if type pkg &>/dev/null; then
		echo "Updating pkg..."
		$SUDO pkg update && $SUDO pkg upgrade
	fi
	if type nix-channel &>/dev/null; then
		echo "Updating nix..."
		nix-channel --update && nix-env -u
	fi
	if type flatpak &>/dev/null; then
		echo "Updating flatpak..."
		flatpak update
	fi
	if type snap &>/dev/null; then
		echo "Updating snap..."
		$SUDO snap refresh
	fi
	if type brew &>/dev/null; then
		echo "Updating brew..."
		brew update
		brew upgrade
		if [ "$(uname)" = "Darwin" ]; then
			brew upgrade --cask --greedy
		fi
		brew autoremove
	fi
	if type port &>/dev/null; then
		echo "Updating port..."
		$SUDO port selfupdate && $SUDO port upgrade outdated
	fi
	omz update
	echo "Updated!"
}

# ADDS CUSTOM KUBECONFIG FILES TO CONTEXT
# TO SWITCH CONTEXTS AND NAMESPACES USE https://github.com/ahmetb/kubectx
kube_reload() {
	trap 'trap - ERR; return' ERR
	if ! command -v kubectl >/dev/null 2>&1; then echo "kubectl is not installed"; return 1; fi
	# if ! command -v kubectx >/dev/null 2>&1 || ! command -v kubens >/dev/null 2>&1; then echo "kubectx/kubens is not installed"; return 1; fi
	silent="false"
	while [ $# -gt 0 ]; do
		case "$1" in
			-s|--silent) local silent="true" ;;
			-f|--fresh) local fresh="true" ;;
			-h|--help) echo "Usage: kube-reload [-s|--silent] [-f|--fresh]"; return 0 ;;
			*) echo "Invalid option: $1"; echo "Usage: kube-reload [-s|--silent]"; return 1 ;;
		esac
		shift
	done
	[ "${silent}" = "false" ] && { echo "Reloading kubeconfigs . . ."; }
	if ! test -d ~/.kube; then
		[ "${silent}" = "false" ] && { echo "No kubeconfig directory found"; }
		return 0
	fi
	export KUBECONFIG=~/.kube/config
	local KUBECONFIG_LIST=""
	local KUBECONFIG_MD5_FILE=~/.kube/.md5
	local KUBECONFIG_TMP1_FILE=/tmp/kubeconfig1
	local KUBECONFIG_TMP2_FILE=/tmp/kubeconfig2
	touch "${KUBECONFIG}"
	touch "${KUBECONFIG_MD5_FILE}"
	local custom_contexts_dir=~/.kube/custom-contexts
	mkdir -p ~/.kube/custom-contexts
	local custom_contexts_dir="$(cd "${custom_contexts_dir}" && pwd)"
	[ "${silent}" = "false" ] && { echo "Custom Contexts Directory: '${custom_contexts_dir}'"; }
	for file in $(find ~/.kube/custom-contexts/ -name '*.config' \( -type f -o -type l \)); do
		[ "${silent}" = "false" ] && { printf "\t${file}\n" | sed -E "s|${custom_contexts_dir}|\.|"; }
		local file="$(echo "${file}" | sed "s/\/\//\//")" # replace double slashes to single
		local KUBECONFIG_LIST="${KUBECONFIG_LIST}:${file}"
	done
	if [ "${KUBECONFIG_LIST}" = "" ]; then
		[ "${silent}" = "false" ] && { echo "No custom kubeconfigs found"; }
		return 0
	fi
	KUBECONFIG="${KUBECONFIG_LIST}" kubectl config view --raw --flatten | sed -E '/^\s*(current-context|namespace):/d' >"${KUBECONFIG_TMP1_FILE}"
	local KUBECONFIG_MD5="$(md5sum "${KUBECONFIG_TMP1_FILE}" | awk '{print $1}')"
	if [ "${fresh}" = "true" ]; then
		echo "" >"${KUBECONFIG_MD5_FILE}"
		[ "${silent}" = "false" ] && { echo "Creating fresh kubeconfig file"; }
	fi
	local KUBECONFIG_MD5_OLD="$(cat ${KUBECONFIG_MD5_FILE})"
	if [ "${KUBECONFIG_MD5}" = "${KUBECONFIG_MD5_OLD}" ]; then
		rm -f "${KUBECONFIG_TMP1_FILE}"
		[ "${silent}" = "false" ] && { echo "No changes detected"; }
		return 0
	fi
	mv "${KUBECONFIG_TMP1_FILE}" "${KUBECONFIG}"
	echo "${KUBECONFIG_MD5}" >"${KUBECONFIG_MD5_FILE}"
	[ "${silent}" = "false" ] && { echo "All contexts successfully joined into '${KUBECONFIG}'"; }
	return 0
}
alias kube-reload="kube_reload"
kube-reload -s

if type brew >/dev/null 2>&1; then
	if [ "${HOMEBREW_PREFIX}" != "$(brew --prefix)" ]; then
		echo "ERROR: Failed to source Homebrew."
	fi
	# macOS HOMEBREW
	export PATH="${HOMEBREW_PREFIX}/sbin:$PATH"
fi

## PYENV NOTES
	## INSTALL PYENV
		# brew install pyenv
		# pyenv install 2.7.16
		# pyenv versions
		# pyenv global 2.7.16   --- OR --- pyenv local 2.7.16
	## VIRTUAL ENVIRONMENT
		# brew install pyenv-virtualenv
		# pyenv virtualenv 3.6.4 myvirtualenv
		# pyenv global myvirtualenv
	## REMOVE VIRTUAL ENVIRONMENT
		# pyenv uninstall myvirtualenv
		# pyenv virtualenv-delete 3.6.4/envs/myvirtualenv
	## UPDATE PYENV VERSIONS
		# pyenv update && (cd $(pyenv root) && git pull)
if test -d $HOME/.pyenv/bin; then
	export PATH="$HOME/.pyenv/bin:$PATH"
fi
if command -v pyenv 1>/dev/null 2>&1; then
	eval "$(pyenv init --path)"
	export PYENV_ROOT="$(pyenv root)"
fi

# SET JAVA HOME
if /usr/libexec/java_home >/dev/null 2>&1; then
	set_java_home() {
		JAVA_TMP_HOME=$(/usr/libexec/java_home -v$2 -F 2>/dev/null || true)
		[ "${JAVA_TMP_HOME}" != "" ] || return 0
		export JAVA_${1}_HOME="${JAVA_TMP_HOME}"
		export JAVA_HOME="${JAVA_TMP_HOME}"
		alias java${1}="export JAVA_HOME=\"${JAVA_TMP_HOME}\""
	}
	# IN ORDER OF LEAST DESIRED DEFAULT
	set_java_home 7 1.7
	set_java_home 8 1.8
	set_java_home 17 17.0
	set_java_home 11 11.0
fi

# WSL EXECUTABLE PATHS
if test -d /mnt/c; then
	export PATH="/mnt/c/Windows/System32:$PATH"
	export PATH="/mnt/c/Users/jonathaf/AppData/Local/Microsoft/WindowsApps:$PATH"
fi

# NODE PATHS
if test -d $HOME/.npm-packages/bin; then
	export PATH="$HOME/.npm-packages/bin:$PATH"
fi

# SETUP BREW
if type brew &>/dev/null; then
	if [ "$(uname)" = "Darwin" ]; then
		export PATH="${HOMEBREW_PREFIX}/bin:$PATH"
		export PATH="${HOMEBREW_PREFIX}/opt/mysql-client@5.7/bin:$PATH"
		export PATH="${HOMEBREW_PREFIX}/opt/findutils/libexec/gnubin:$PATH" # USE GNU FIND (must first do: brew install findutils)
		export PATH="${HOMEBREW_PREFIX}/opt/gnu-sed/libexec/gnubin:$PATH" # USE GNU SED (must first do: brew install gnu-sed)
		export PATH="${HOMEBREW_PREFIX}/opt/gnu-tar/libexec/gnubin:$PATH" # USE GNU TAR (must first do: brew install gnu-tar)
		export PATH="${HOMEBREW_PREFIX}/opt/gnu-getopt/bin:$PATH" # USE GNU GETOPT (must first do: brew install getopt)
		export PATH="${HOMEBREW_PREFIX}/opt/coreutils/libexec/gnubin:$PATH" # USE GNU READLINK (must first do: brew install coreutils)
		export PATH="${HOMEBREW_PREFIX}/opt/grep/libexec/gnubin:$PATH" # USE GNU GREP (must first do: brew install grep)
		export PATH="${HOMEBREW_PREFIX}/opt/gnupg@2.2/bin:$PATH" # USE LEGACY GPG
		export PATH="${HOMEBREW_PREFIX}/opt/helm@2/bin:$PATH" # NEED TO RUN 'helm init --client-only' AFTER INSTALLING
		alias gnu-grep="${HOMEBREW_PREFIX}/opt/grep/libexec/gnubin/grep --color=auto"
		alias brewu='brew update; brew upgrade; brew upgrade --cask --greedy; brew autoremove'
	else
		alias brewu='brew update; brew upgrade; brew autoremove'
	fi
fi

export PATH="$HOME/.local/bin:$PATH"

# LOAD KUBESWITCHER
type switcher &>/dev/null && source <(switcher init zsh)
type switch &>/dev/null && source <(switch completion zsh)

# # FUNCTION TO ALLOW yq WITHOUT EXTRA ARGS
# if type yq &>/dev/null; then
# 	function yq() {
# 		if [[ "$@" == "" ]]; then
# 			if ! type pygmentize &>/dev/null; then
# 				echo "pygmentize not found: pip install Pygments"
# 				return 1
# 			fi
# 			command yq --yaml-output | pygmentize -l yaml
# 		else
# 			command yq $@
# 		fi
# 	}
# fi

if type velero &>/dev/null; then
	alias v="velero"
fi

# REMOVE SOME OH-MY-ZSH KUBECTL ALIASES
unalias kl 2>/dev/null

if type kubectl &>/dev/null; then
	#alias kubectl="kubectl --insecure-skip-tls-verify"
	alias k="kubectl --insecure-skip-tls-verify"
	# if type kubectx &>/dev/null; then
	# 	alias kx="kubectx"
	# 	alias kn="kubens"
	# fi

	alias kge="kubectl get events -w"

	alias kga="kubectl get \$(kubectl api-resources --namespaced=true --output=name | grep -v -E '^(events|rolebindings|externalmetrics)(\.|$)' | tr '\n' ',' | sed 's/,$/\n/') 2>&1 | grep -v 'MethodNotAllowed'"

	ky () {
		kubectl "$@" -o yaml | bat -l yaml --paging=never --style=plain
	}

	if type switcher &>/dev/null; then
		alias kx="touch ~/.kube/.switched && switch set-context"
		alias kn="switch namespace"
		alias kxu="rm -f ~/.kube/.switched && switch unset-context"
		alias kxl="switch list-contexts"
		alias knl="kubectl get namespace --no-headers | awk '{print \$1}'"
		if [ -f ~/.kube/.switched ]; then
			switch set-last-context >/dev/null 2>&1 || true
		fi
	fi

	# TEST ALL KUBECONFIGS
	kx_test() {
		ERROR_LOG_FILE="/tmp/kx_test-error.log"
		RED='\033[0;31m'
		GREEN='\033[0;32m'
		BLUE='\033[0;34m'
		NC='\033[0m' # NO COLOR
		find ~/.kube/custom-contexts/ -name '*.config' \( -type f -o -type l \) | while read -r k; do
			rm -f "${ERROR_LOG_FILE}"
			CLUSTER_NAME="$(KUBECONFIG=$k kubectl config view -o jsonpath='{.clusters[].name}')"
			PROGRESS_LINE="--- ${CLUSTER_NAME} ---"
			tput civis # HIDE CURSOR
			printf "${BLUE}${PROGRESS_LINE} ⏳${NC}"
			KUBECONFIG=$k kubectl get namespaces >/dev/null 2>"${ERROR_LOG_FILE}"
			if [ $? != 0 ] || grep -q '[^[:space:]]' "${ERROR_LOG_FILE}"; then
				KUBECONFIG_ERROR=true
				printf "\r\033[K${RED}${PROGRESS_LINE} ❌${NC}\n"
				cat "${ERROR_LOG_FILE}"
			else
				printf "\r\033[K${GREEN}${PROGRESS_LINE} ✅${NC}\n"
			fi
			tput cnorm # SHOW CURSOR
			rm -f "${ERROR_LOG_FILE}"
		done
		if [ "${KUBECONFIG_ERROR}" = "true" ]; then
			return 1
		fi
	}
	alias kx-test="kx_test"
	alias kube-test="kx_test"

	# KUBERNETES GET CURRENT NAMESPACE
	kgn() {
		NAMESPACE_CONTEXT="$(kubectl config view --minify --output 'jsonpath={..namespace}')"
		echo "${NAMESPACE_CONTEXT}"
	}

	# KUBERNETES CLUSTER INFO
	ki() {
		# CLUSTER_NAME="$(kubectl get daemonset instana-agent -n instana-agent -o jsonpath='{.spec.template.spec.containers[*].env[?(@.name=="INSTANA_KUBERNETES_CLUSTER_NAME")].value}')"
		CLUSTER_NAME="$(kubectl config view --minify -o jsonpath='{.clusters[].name}{"\n"}')"
		# CLUSTER_API_URL="$(kubectl cluster-info | sed -r "s/\x1B\[[0-9;]*[mK]//g" | grep 'Kubernetes control plane' | sed 's/.*is running at //' | sed 's|/k8s/clusters/|/dashboard/c/|')"
		CLUSTER_API_URL_FULL="$(kubectl config view --minify -o json | jq -r '.clusters[].cluster.server')"
		CLUSTER_SCHEMA="$(echo "${CLUSTER_API_URL_FULL}" | sed -E 's/^(https?).*/\1/')"
		CLUSTER_API_URL="$(echo "${CLUSTER_API_URL_FULL}" | sed -E 's/^https?:\/\///')"
		CLUSTER_WEB_URL="$(echo "${CLUSTER_API_URL_FULL}" | sed 's|/k8s/clusters/|/dashboard/c/|')"
		CLUSTER_PLAYBOOK_URL="$(echo "${CLUSTER_API_URL_FULL}" | sed -E 's/^https?:\/\///' | sed 's|/k8s/clusters/|/c/|')"
		AMBASSADOR_ID="$(kubectl get host -n ambassador -o json 2>/dev/null | jq -r '.items[] | select(.metadata.name | startswith("aes-internal-host-") and endswith("-cloudone-netapp-com")) | select(.metadata.name != "aes-internal-host-cloudone-netapp-com") | .spec.hostname' | grep -o -E 'prd[0-9]+')"
		KONG_ID="$(k get ingress -n kong-examples -o json | jq -r '.items[] | select(.spec.ingressClassName == "kong-internal") | .spec.rules[0].host' | grep -o -E 'gw[0-9]+' | head -n1)"
		NAMESPACE_CONTEXT="$(kubectl config view --minify --output 'jsonpath={..namespace}')"
		(
			printf "Cluster Name:~${CLUSTER_NAME}\n"
			printf "Cluster API URL:~${CLUSTER_API_URL_FULL}\n"
			printf "Cluster Web URL:~${CLUSTER_WEB_URL}\n"
			printf "Cluster Playbook URL:~${CLUSTER_PLAYBOOK_URL}\n"
			printf "Cluster Schema:~${CLUSTER_SCHEMA}\n"
			printf "Ambassador ID:~${AMBASSADOR_ID}\n"
			printf "Kong ID:~${KONG_ID}\n"
			printf "Namespace:~${NAMESPACE_CONTEXT}\n"
		) | column -t -s '~'
	}

	# KUBECTL EXEC FUNCTION
	ke() {
		[ $# -eq 0 ] && { echo "You need to specify the service name"; return 1; }
		SERVICE_NAME=$1; shift
		# set -x
		pod_name="$(kubectl get pods -l app.kubernetes.io/name=${SERVICE_NAME} -o jsonpath='{.items[0].metadata.name}')"
		if [ $# -eq 0 ]; then
			if ! kubectl exec -it "${pod_name}" -- bash 2>/dev/null; then
				if ! kubectl exec -it "${pod_name}" -- ash 2>/dev/null; then
					kubectl exec -it "${pod_name}" -- sh
				fi
			fi
		else
			kubectl exec -it "${pod_name}" -- "$@"
		fi
		{ set +x; } 2>/dev/null
	}
	if type compdef &>/dev/null; then
		_ke() { _arguments "1: :($(kubectl get po -o jsonpath='{range .items[*]}{.metadata.labels.app\.kubernetes\.io/name}{"\n"}{end}' | sort | uniq))"; }
		compdef _ke ke
	fi

	# KUBECTL POD LOGS
	kl() {
		set -x
		kubectl logs --all-containers=true --ignore-errors=true --tail -1 -f -l app.kubernetes.io/name=$@;
		{ set +x; } 2>/dev/null
	}
	if type compdef &>/dev/null; then
		_kl() {
			apps=$(kubectl get po -o jsonpath='{range .items[*]}{.metadata.labels.app\.kubernetes\.io\/name}{"\n"}{end}' | sort | uniq)
			_arguments "1: :(${apps})";
		}
		compdef _kl kl
	fi

	# DECODES A K8S SECRET
	ks() {
		secret_name=$1
		secret_data="$(kubectl get secret ${secret_name} -o json | jq -r '.data')"
		secret_decoded='{}'
		printf '%s' "${secret_data}" | jq -r '. | keys[]' | while read -r key; do
			val="$(printf '%s' "${secret_data}" | jq -r --arg key $key '.[$key]' | base64 -d)"
			if ! printf "%s" "${val}" | awk '/[^\x00-\x7F]/ { exit 1 }'; then
				val="<<<non-ascii-data>>>"
			fi
			secret_decoded="$(printf '%s' "${secret_decoded}" | jq --arg key "${key}" --arg val "${val}" '. += {($key): $val}')"
		done
		kubectl get secret ${secret_name} -o json | jq --argjson secret_decoded "${secret_decoded}" '. | .["data"] = $secret_decoded' | jq 'del(.metadata.annotations["kubectl.kubernetes.io/last-applied-configuration"])'
	}
	if type compdef &>/dev/null; then
		_ks() { _arguments "1: :($(kubectl get secret -o jsonpath='{.items[*].metadata.name}'))"; }
		compdef _ks ks
	fi

	# DISPLAYS ALL K8S RESOURCES
	kr() {
		kubectl get $(kubectl api-resources --namespaced=true --output=name | grep -v -E '^events(\.|$)' | tr '\n' ',' | sed 's/,$/\n/') 2>&1 | grep -v 'MethodNotAllowed'
	}

	# KUBECTL PORT-FOWARD FUNCTION
	kf() {
		[ $# -eq 0 ] && { echo "You need to specify the service name"; return 1; }
		INSTANCE_NAME=$1; shift
		[ $# -eq 0 ] || { ARGS=("$@"); }
		APP_LABEL="$(kubectl get ${INSTANCE_NAME} -o jsonpath='{.metadata.labels.app}')"
		PORT_LIST="$(kubectl get services --selector=app=${APP_LABEL} -o json | jq -r '.items[].spec.ports[].port')"
		PORT_MAPPING=${PORT_LIST}:${PORT_LIST}
		set -x
		kubectl port-forward ${INSTANCE_NAME} --address 0.0.0.0 ${PORT_MAPPING}
		{ set +x; } 2>/dev/null
	}
	if type compdef &>/dev/null; then
		_kf() { _arguments "1: :($(kubectl get deployment,sts --no-headers | awk '{print $1}' | sed 's/\.apps//'))"; }
		compdef _kf kf
	fi
fi

if type rancher &>/dev/null; then
	rancher_login() {
		local CONTEXT_SERVER="$(kubectl config view --minify -o json | jq -r '.clusters[0].cluster.server')"
		local CONTEXT_TOKEN="$(kubectl config view --raw --minify -o json | jq -r '.users[0].user.token')"
		local CONTEXT_NAMESPACE="$(kubectl config view --minify -o json | jq -r '.contexts[0].context.namespace //empty')"
		local CONTEXT_CLUSTERID="$(k config view --minify -o json | jq -r '.clusters[0].cluster.server' | sed -E 's/.*\/(c-[^\/ ]*$)/\1/')"
		local RANDOM_PROJECT_ENTRY="$((timeout -s SIGINT 2 rancher login "${CONTEXT_SERVER}" --token "${CONTEXT_TOKEN}" 2>&1 || true) | grep " ${CONTEXT_CLUSTERID}:" | head -n 1 | awk '{print $1}')"
		echo "Authenticating to '${CONTEXT_SERVER}'"
		echo "${RANDOM_PROJECT_ENTRY}" | rancher login "${CONTEXT_SERVER}" --token "${CONTEXT_TOKEN}" | grep -v -E '^[0-9]+ ' | grep -v '^NUMBER' | grep -v '^Select'
	}
	alias rancher-login="rancher_login"
fi

if type kubectl &>/dev/null; then
	# # FUNCTION TO SEARCH ALL CLUSTERS FOR NAMESPACE
	# kxn() {
	# 	SEARCH_NS="$1"
	# 	NS_RESULTS_COMBINED=""
	# 	if [ "${SEARCH_NS}" = "" ]; then
	# 		echo "You need to specify the namespace search filter"
	# 		return 1
	# 	fi
	# 	find ~/.kube/custom-contexts -name "*.config" -type f | while read -r KUBECONFIG_FILE; do
	# 		NS_RESULTS="$(KUBECONFIG="${KUBECONFIG_FILE}" kubectl get ns | awk '{print $1}' | grep ${SEARCH_NS})"
	# 		if [ "${NS_RESULTS}" != "" ]; then
	# 			CURRENT_CONTEXT="$(KUBECONFIG="${KUBECONFIG_FILE}" kubectl config current-context)"
	# 			NS_RESULTS_COMBINED="$(echo "${NS_RESULTS_COMBINED}\n${NS_RESULTS}" | sed -e '/^$/d')"
	# 			# CLUSTER_NAME="$(KUBECONFIG="${KUBECONFIG_FILE}" kubectl config view --minify -o jsonpath='{.clusters[].name}{"\n"}')"
	# 			echo "${CURRENT_CONTEXT}"
	# 			echo "${NS_RESULTS}" | sed -e 's/^/- /'
	# 		fi
	# 	done
	# 	NS_RESULTS_COMBINED="$(echo "${NS_RESULTS_COMBINED}" | sed -e '/^$/d')"
	# 	NS_RESULTS_COMBINED_COUNT="$(echo "${NS_RESULTS_COMBINED}" | sed -e '/^$/d' | wc -l)"
	# 	if [ ${NS_RESULTS_COMBINED_COUNT} -eq 0 ]; then
	# 		echo "Namespace not found in any clusters"
	# 		return 1
	# 	elif [ ${NS_RESULTS_COMBINED_COUNT} -gt 1 ]; then
	# 		echo "Multiple namespaces found. Unable to set context."
	# 		return 1
	# 	elif [ ${NS_RESULTS_COMBINED_COUNT} -eq 1 ]; then
	# 		kx "${CURRENT_CONTEXT}"
	# 		kn "${NS_RESULTS_COMBINED}"
	# 		return
	# 	else
	# 		echo "There was an error"
	# 		return 1
	# 	fi
	# }

	# FUNCTION TO SEARCH ALL CLUSTERS FOR NAMESPACE
	kxn() {
		SEARCH_NS="$1"
		if [ "${SEARCH_NS}" = "" ]; then
			echo "You need to specify the namespace search filter"
			return 1
		fi
		all_namespaces="$(km -o json -- get ns)"
		# all_namespaces="$(cat /tmp/test.json)"
		filtered_namespaces="$(printf '%s' "${all_namespaces}" | jq -r --arg regexp "${SEARCH_NS}" '[to_entries[] | select(any(.value.items[]; .metadata.name | test($regexp)))] | .[].value.items |= map(select(.metadata.name | test($regexp)))')"
		num_namespaces="$(printf '%s' "${filtered_namespaces}" | jq -r '[.[].value.items[]] | length')"
		if [ "${num_namespaces}" -eq 0 ]; then
			echo "No namespaces found in any cluster matching '${SEARCH_NS}'"
			return 1
		fi
		formatted_namespaces="$(printf '%s' "${filtered_namespaces}" | jq -r '.[] | .key, (.value.items[] | "- \(.metadata.name)")')"
		printf '%s\n' "${formatted_namespaces}"
		if [ "${num_namespaces}" -gt 1 ]; then
			echo
			echo "Found ${num_namespaces} namespaces. Unable to set context."
			return 1
		elif [ "${num_namespaces}" -eq 1 ]; then
			FOUND_CONTEXT="$(printf '%s' "${filtered_namespaces}" | jq -r '.[0].key')"
			FOUND_NAMESPACE="$(printf '%s' "${filtered_namespaces}" | jq -r '.[0].value.items[0].metadata.name')"
			kx "${FOUND_CONTEXT}"
			kn "${FOUND_NAMESPACE}"
			return
		else
			echo "Unknown error"
			return 1
		fi
	}
fi

if type velero &>/dev/null; then
	alias v="velero"
fi

if type nix &>/dev/null; then
	alias nixu="nix-channel --update && nix-env -u '*'"
	alias nix-autoremove="nix-collect-garbage -d"
fi

if [ -f ~/.ansible.cfg.sh ]; then source ~/.ansible.cfg.sh; fi

if type ansible-playbook &>/dev/null; then
	export ANSIBLE_FORCE_COLOR=True
	# alias ansible-playbook='rm -f $ANSIBLE_LOG_PATH; ansible-playbook'
	# REQUIRED FOR CONJUR IN PLAYBOOKS
	[ "$(uname -s)" = "Darwin" ] && export OBJC_DISABLE_INITIALIZE_FORK_SAFETY=YES
	[ "${LANG}" = "" ] && export LANG=en_US.UTF-8
fi

# FIX VISUAL STUDIO CODE SERVER KEYCHAIN ERROR
export VSCODE_CLI_USE_FILE_KEYCHAIN=1

# RANCHER DESKTOP
test -d ~/.rd/bin && export PATH="$(cd ~ && pwd)/.rd/bin:$PATH"

# KUBECTL KREW
if test -d ~/.krew/bin; then
	export PATH="${KREW_ROOT:-$HOME/.krew}/bin:$PATH"
	alias krew="kubectl krew"
fi

alias km="kubectl mc"

test -f ~/.sh_profile_local && { source ~/.sh_profile_local; } || true

# ENABLE COLORS
TERM=xterm-256color

# REMOVE DUPLICATE PATHS
export PATH="$(perl -e 'print join(":", grep { not $seen{$_}++ } split(/:/, $ENV{PATH}))')"

# sleep 0.1
# clear
# tpu
